{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from tools import memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rnet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.array([1,2], dtype=np.float32)\n",
    "\n",
    "\n",
    "test_weight = np.array([[1,2]\n",
    "                        ,[3,4]], dtype=np.float32)\n",
    "\n",
    "test_bias = np.array([1,2], dtype=np.float32)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in = 2,out = 2, params=6) \n",
      "Linear(in_features=2, out_features=2, bias=True)\n"
     ]
    }
   ],
   "source": [
    "my_linear_layer = rnet.Linear(in_features=2, out_features=2, is_bias=True)\n",
    "torch_linear_layer =  nn.Linear(2, 2)\n",
    "\n",
    "print(my_linear_layer)\n",
    "print(torch_linear_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "origin wights :\n",
      "[[0.9744315  0.8054147 ]\n",
      " [0.8874335  0.23286068]]\n",
      "    ---------------------\n",
      "[0.51147157 0.11441487]\n",
      "\n",
      "torch weights, bias:\n",
      "tensor([[-0.2332, -0.6911],\n",
      "        [-0.4209, -0.3538]])\n",
      "tensor([-0.3860, -0.0862])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "origin wights :\n",
    "{my_linear_layer.weight}\n",
    "    ---------------------\n",
    "{my_linear_layer.bias}\n",
    "\n",
    "torch weights, bias:\n",
    "{torch_linear_layer.weight.data}\n",
    "{torch_linear_layer.bias.data}\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_linear_layer.weight: \n",
      " [[1. 2.]\n",
      " [3. 4.]] \n",
      " torch_linear_layer.weight: \n",
      " Parameter containing:\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]], requires_grad=True) \n",
      "\n",
      " my_linear_layer.bias: \n",
      " [1. 2.] \n",
      " torch_linear_layer.bias: \n",
      " Parameter containing:\n",
      "tensor([1., 2.], requires_grad=True) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_linear_layer.weight = test_weight\n",
    "torch_linear_layer.weight = nn.Parameter(torch.tensor(test_weight, dtype=torch.float32))\n",
    "\n",
    "my_linear_layer.bias = test_bias\n",
    "torch_linear_layer.bias = nn.Parameter(torch.tensor(test_bias, dtype=torch.float32))\n",
    "\n",
    "\n",
    "print(\n",
    "    \"my_linear_layer.weight: \\n\", my_linear_layer.weight, \"\\n\",\n",
    "    \"torch_linear_layer.weight: \\n\", torch_linear_layer.weight, \"\\n\\n\",\n",
    "    \"my_linear_layer.bias: \\n\", my_linear_layer.bias, \"\\n\",\n",
    "    \"torch_linear_layer.bias: \\n\", torch_linear_layer.bias, \"\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original product:\n",
      " [ 6. 13.],\n",
      "PyTorch product:\n",
      " tensor([ 6., 13.], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "my_product = my_linear_layer(array)\n",
    "torch_product = torch_linear_layer(torch.tensor(array, dtype=torch.float32))\n",
    "\n",
    "print(\n",
    "    f\"Original product:\\n {my_product},\\n\"\n",
    "    f\"PyTorch product:\\n {torch_product}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6., 13.], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(array @ my_linear_layer.weight.T) + my_linear_layer.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6., 13.], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( torch.tensor(array, dtype = torch.float32) @ torch_linear_layer.weight.detach().T) + nn.Parameter(torch_linear_layer.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(20,3)\n",
    "# y = np.random.randint(0,3,20)\n",
    "y = np.random.randint(0,3,20)\n",
    "# print(y)\n",
    "y_c = np.eye(20,3)[y]\n",
    "# print(y_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rnet import Linear, Neuaral\n",
    "from tools import relu\n",
    "\n",
    "\n",
    "class MySimpleNN(rnet.Neuaral):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(MySimpleNN, self).__init__()\n",
    "        self.fc1 = rnet.Linear(input_size, 100)  # First fully connected layer\n",
    "        self.fc2 = rnet.Linear(100, output_size)  # Second fully connected layer\n",
    "        pass\n",
    "\n",
    "    def forward(self, x : np.ndarray):\n",
    "        x = relu(self.fc1(x))  # Apply ReLU activation after the first layer\n",
    "        x = self.fc2(x)  # Output layer\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Define the neural network model\n",
    "class TorchSimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(TorchSimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 100)  # First fully connected layer\n",
    "        self.fc2 = nn.Linear(100, output_size)  # Second fully connected layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))  # Apply ReLU activation after the first layer\n",
    "        x = self.fc2(x)  # Output layer\n",
    "        return x\n",
    "\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "# model = SimpleNN(input_size, hidden_size, output_size)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# # Training loop\n",
    "# for epoch in range(100):  # Train for 100 epochs\n",
    "#     for inputs, labels in dataloader:\n",
    "#         # Forward pass\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "        \n",
    "#         # Backward pass and optimization\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#     # Print loss every 10 epochs\n",
    "#     if (epoch + 1) % 10 == 0:\n",
    "#         print(f'Epoch [{epoch+1}/100], Loss: {loss.item():.4f}')\n",
    "\n",
    "# # Example prediction\n",
    "# with torch.no_grad():\n",
    "#     example_input = torch.tensor([[0.5, -0.5]])\n",
    "#     output = model(example_input)\n",
    "#     predicted = torch.argmax(output, dim=1)\n",
    "#     print(f'Predicted class: {predicted.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data (for demonstration purposes)\n",
    "# Assuming input size is 2, output size is 2 (for binary classification)\n",
    "input_size = 20\n",
    "hidden_size = 50\n",
    "output_size = 20\n",
    "\n",
    "# Generate some random data\n",
    "X = torch.randn(1000, input_size)  # 100 samples, 2 features each\n",
    "y = torch.randint(0, output_size, (1000,))  # 100 labels (0 or 1)\n",
    "\n",
    "# Create DataLoader\n",
    "# dataset = TensorDataset(X, y)\n",
    "# dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "torch_model = TorchSimpleNN(input_size, output_size)\n",
    "my_model = MySimpleNN(input_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@memory\n",
    "def test_mine():\n",
    "    # Test the mine function\n",
    "    for i in range(10):\n",
    "        for inputs, labels in zip(X,y):\n",
    "            my_model(inputs)\n",
    "\n",
    "@memory\n",
    "def test_torch():\n",
    "    # Test the mine function\n",
    "    for i in range(10):\n",
    "        for inputs, labels in zip(X,y):\n",
    "            torch_model(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of test_mine: 0.25 MB\n"
     ]
    }
   ],
   "source": [
    "test_mine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of test_torch: 0.14 MB\n"
     ]
    }
   ],
   "source": [
    "test_torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vir-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
